{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Benzene Price Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Notes and Explainations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses SQL to query::\n",
    "* lyb-sql-devdacore-002.5bff9fcb8330.database.windows.net \n",
    "    * To extract the information contained in the t-code ZMRRELPO\n",
    "* lyb-sql-prddacore-002.bed79ae4ef8b.database.windows.net\n",
    "    * To extract ZEMA IHS data\n",
    "    * To extract ZEMA ICIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook utilizes the py37_benzene environment which can be installed via the Anaconda Prompt from your local repo sync by running:\n",
    "> conda env create -f py37_benzene.yml\n",
    "\n",
    "This .yml file is stored in the root scripts directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Prepare Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Standard Libraries and configure runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Import Basic Python DS Libraries \n",
    "import pandas as pd     # Standard data science package\n",
    "import numpy as np      # Additional numerical functions\n",
    "#import dtale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##\n",
    "# Import Advanced Python DS Libraries\n",
    "import missingno as msno    # Missing value toolbox\n",
    "#from pandas_profiling import ProfileReport     # Integrated/deep reporting, resource intensive\n",
    "from statsmodels.tsa.stattools import adfuller  # Statistical test for stationary data\n",
    "\n",
    "##\n",
    "# Import Database Connection Libraries\n",
    "#import pyodbc           # Database connector\n",
    "\n",
    "##\n",
    "# Import Plotting Libraries\n",
    "import matplotlib.pyplot as plt                # Full featured plotting toolbox\n",
    "plt.rcParams['figure.figsize'] = (25,8)\n",
    "#import plotly.graph_objects as go               #Plotly GO toolbox\n",
    "import plotly.express as px                    # Plotly Express plotting toolbox\n",
    "import plotly.io as pio                        # Addtional Controls for plotly to allow visuals within VSCode Notebook\n",
    "#import seaborn as sns       # Seaborn plotting toolbox\n",
    "\n",
    "##\n",
    "# Import Operating System Interface Libraries\n",
    "import os       # operating system interface\n",
    "import sys\n",
    "#import calendar\n",
    "#import datetime as dt\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "##\n",
    "# Import File Format Libraries\n",
    "#import pyarrow.feather as feather       # Advanced datasource import/export toolbox (Apache Parquet)\n",
    "import shelve # Allows serialization (pickle-ing) of multiple opjects and saving them to dict objects for later use\n",
    "import sqlite3\n",
    "##\n",
    "# Import ML and Forecasting Libraries\n",
    "#from scipy import interpolate\n",
    "#from sklearn import metrics     # Metrics for sklearn ML models\n",
    "from sklearn.ensemble import RandomForestRegressor # ML Model package\n",
    "#from sklearn.tree import DecisionTreeRegressor  # ML Model package\n",
    "\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter, SlidingWindowSplitter\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#from sktime.forecasting.model_selection import ForecastingGridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "#from xgboost import XGBRegressor, XGBRFRegressor\n",
    "#from prophet import Prophet\n",
    "\n",
    "##\n",
    "# Setup packages for sending messages\n",
    "import requests\n",
    "import json\n",
    "\n",
    "##\n",
    "# Import timing function(s)\n",
    "from time import perf_counter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Libraries\n",
    "pio.renderers.default = \"notebook_connected\" # Configure plotly to print within VSCode environment\n",
    "#pio.renderers.default = \"vscode\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Run Environment\n",
    "AllLPC = True # Used in the \"Deal with non-Stationary data\" step to ensure that e take the Percent Change for every column and not just those that are non-stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added c:\\Users\\baanders\\Documents\\Benzene Forecasting\\Scripts\\Functions to system paths\n",
      "Loaded multiplot\n",
      "Loaded multiplot\n",
      "Loaded StationaryTools\n",
      "Loaded StationaryTools\n",
      "Loaded RegressionTools\n",
      "Failed to load NaiveTools\n",
      "Loaded ModelingTools\n",
      "Loaded sk_ts_modelfit\n"
     ]
    }
   ],
   "source": [
    "# Define location for custom functions\n",
    "module_path = os.path.abspath(os.path.join('../Functions'))\n",
    "\n",
    "# Verify it's accessible for loading\n",
    "if (module_path not in sys.path) & (os.path.isdir(module_path)):\n",
    "    sys.path.append(module_path)\n",
    "    print('Added', module_path, 'to system paths')\n",
    "\n",
    "elif (module_path in sys.path) & (os.path.isdir(module_path)):\n",
    "    print(module_path, 'ready to be used for import')\n",
    "\n",
    "else:\n",
    "    print(module_path, 'is not a valid path')\n",
    "\n",
    "# Import Custom Functions\n",
    "try: from multi_plot import *; print('Loaded multiplot')\n",
    "except: print('failed to load multi_plot')\n",
    "\n",
    "try: from StationaryTools import *; print('Loaded StationaryTools')\n",
    "except: print('Failed to load StationaryTools')\n",
    "\n",
    "try: from RegressionTools import *; print('Loaded RegressionTools')\n",
    "except: print('Failed to load RegressionTools')\n",
    "\n",
    "try: from NaiveForecasting import *; print('Loaded NaiveTools')\n",
    "except: print('Failed to load NaiveTools')\n",
    "\n",
    "try: from ModelingTools import *; print(\"Loaded ModelingTools\")\n",
    "except: print('ModelingTools failed to load')\n",
    "\n",
    "try: from  sk_ts_modelfit import *; print('Loaded sk_ts_modelfit')\n",
    "except: print('Failed to load sk_ts_modelfit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Configure messaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://lyondellbasell.webhook.office.com/webhookb2/0b44f724-4c38-4322-af43-1cc8a79b2240@fbe62081-06d8-481d-baa0-34149cfefa5f/IncomingWebhook/7d6ffad65b414df9bd9bf5fa64da44b2/76b3b453-0a85-40ff-a5d7-15d042decdf6'\n",
    "\n",
    "#payload = {\n",
    "#    \"text\": \"Sample alert text\"\n",
    "#}\n",
    "#headers = {\n",
    "#    'Content-Type': 'application/json'\n",
    "#}\n",
    "#response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "#print(response.text.encode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default storage location for files\n",
    "dataroot = '../../Data/Parquet/SKLearn Data/'\n",
    "ifilename = '20220426_weekly_for_modeling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220426_weekly_for_modeling dataset loaded with shape (369, 5306) and 0 NaN values\n"
     ]
    }
   ],
   "source": [
    "# Check if data location above exists. If it does import dataset.\n",
    "# All datasets imported with name df so that we can generically \n",
    "\n",
    "if os.path.isdir(dataroot):\n",
    "    df = pd.read_parquet(dataroot+ifilename+'.parquet')\n",
    "    print(ifilename + ' dataset loaded with shape', df.shape, 'and', df.isna().sum().sum(), 'NaN values')\n",
    "    \n",
    "else:\n",
    "    print('Storage location does not exist. Please update directory and try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Limit Columns to be used in fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before droping columns (369, 5306)\n",
      "Shape after droping columns (369, 1568)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before droping columns', df.shape)\n",
    "df = df.loc[:,~df.columns.str.contains('^USD')]\n",
    "df = df.loc[:,~df.columns.str.contains('^....USD')]\n",
    "df = df.loc[:,~df.columns.str.contains('-CLOSE')]\n",
    "df = df.loc[:,~df.columns.str.contains('-HIGH')]\n",
    "df = df.loc[:,~df.columns.str.contains('-HIGHLOW2')]\n",
    "df = df.loc[:,~df.columns.str.contains('-LOW')]\n",
    "\n",
    "print('Shape after droping columns', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Scikit Learn Modeling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Configure Global Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_1',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_2',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_3',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_4',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_5',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_6',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_7',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_8',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_9',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_10',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_11',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_12',\n",
       " 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America_lag_13']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple utility to find a column name based on what it starts with\n",
    "# May need it to find target column values\n",
    "\n",
    "[col for col in df if col.startswith('Benzene-Spot, Current Month, High')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 0 inf or -inf values in df\n",
      "There are: 0 NaN values in df\n"
     ]
    }
   ],
   "source": [
    "# Deal with inf and -inf values before train/test splitting\n",
    "inf_vals = df.isin([np.inf, -np.inf]).sum().sum()\n",
    "nan_vals = df.isna().sum().sum()\n",
    "print('There are:',inf_vals,'inf or -inf values in df')\n",
    "print('There are:',nan_vals,'NaN values in df')\n",
    "if (inf_vals>0) or (nan_vals>0): \n",
    "    df = df.replace([np.inf, -np.inf], np.NaN)\n",
    "    df = df.dropna(axis=0)\n",
    "    inf_vals = df.isin([np.inf, -np.inf]).sum().sum()\n",
    "    nan_vals = df.isna().sum().sum()\n",
    "    print('After conversion there are:', inf_vals,'inf or -inf values in df')\n",
    "    print('After conversion there are:',nan_vals,'NaN values in df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm will attempt to predict:\n",
      "\t Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America \n",
      "using:\n",
      "\t ['date'] \n",
      "based on:\n",
      "\t 1567 predictors\n"
     ]
    }
   ],
   "source": [
    "# Our target and Identifying columns won't change for any of the models so we'll define them once here\n",
    "#target = 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America'\n",
    "target = 'Benzene-Spot, Current Month, High-N/A-Cents per Gallon-FOB Houston, TX-North America'\n",
    "\n",
    "# Our Identifying (IDcol) is 'date' for time series analyses\n",
    "IDcol = ['date']\n",
    "\n",
    "# All columns that are not Targets(predictee's) or ID's(dates) should be used to predict the Target\n",
    "predictors = [x for x in df.columns if x not in [target]+[IDcol]]\n",
    "\n",
    "print(\"Algorithm will attempt to predict:\\n\\t\", target, \"\\nusing:\\n\\t\", IDcol, \"\\nbased on:\\n\\t\", len(predictors), \"predictors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Test for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_corr = df.corr()\n",
    "#keep = np.triu(np.ones(df_corr.shape)).astype('bool').reshape(df_corr.size)\n",
    "#df_corr_long = df_corr.stack()[keep]\n",
    "#df_corr_long[df_corr_long>0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlated_features = set()\n",
    "#correlation_matrix = df.drop(target, axis=1).corr()\n",
    "\n",
    "#for i in range(len(correlation_matrix.columns)):\n",
    "#    for j in range(i):\n",
    "#        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "#            colname = correlation_matrix.columns[i]\n",
    "#            correlated_features.add(colname)\n",
    "\n",
    "#print('# Features in df:',len(df.columns),'\\n# correlated features:',len(correlated_features))\n",
    "\n",
    "# Remove any columns that are correleated\n",
    "#df.drop(columns=correlated_features, inplace=True)\n",
    "#predictors = [x for x in df.columns if x not in [target]+[IDcol]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Extract prefered time frame and lag for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll back if the below has been run and needs to be changed\n",
    "#df = df_full.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start_date for slicing df\n",
    "start_date = '2015-01-01'\n",
    "# Set end_date for slicing df\n",
    "end_date = '2018-12-31'#'2019-12-31'\n",
    "\n",
    "#df_full = df.copy(deep=True)\n",
    "df = df[start_date : end_date]\n",
    "print('Before processing:\\ndf starts on:', df.index[0],'\\n\\tends on:', df.index[-1])\n",
    "\n",
    "# Loop counter used for iterative lagging\n",
    "lcnt = 1 # 4, 8, 12\n",
    "\n",
    "# Add periods to end of dataframe equal to amount of fshift\n",
    "#future = pd.DataFrame(pd.date_range(df.index[-1], periods = lcnt, freq='w')).set_index(0)\n",
    "#future = future.iloc[1:,:]\n",
    "#df = pd.concat([df, future], axis=0)\n",
    "\n",
    "# Shift predictor values forward\n",
    "df[predictors] = df[predictors].shift(lcnt)\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# Remove top _fshift_ rows that are now NaN\n",
    "#df = df.iloc[fshift:,:]\n",
    "\n",
    "# Create dataframe for predictions:\n",
    "#df_pred = df[predictors].iloc[-fshift:,:]\n",
    "\n",
    "# Remove prediction from df\n",
    "#df = df.iloc[:-fshift,:]\n",
    "\n",
    "print('After processing:\\ndf starts on:', df.index[0],'\\n\\tends on:', df.index[-1])\n",
    "#print('\\nfuture starts on:', future.index[0],'\\n\\tends on:', future.index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Scikit Learn Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define alg search params\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 50)] # [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt'] # ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 20)] # [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 50, num = 11)] #[2, 5, 10] # [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4, 5, 10, 20] # [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False] # [True, False]\n",
    "# Define Random Forest Regressor HP grid for DV\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE returned 1398 columns using thise\n",
    "init_params = { 'n_estimators': 787,\n",
    "                'min_samples_split': 6,\n",
    "                'min_samples_leaf': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'max_depth': 41,\n",
    "                'bootstrap': True}\n",
    "\n",
    "# Final pass of search algorithm found this with only 60 RFE columns\n",
    "init_params = {'n_estimators': 714,\n",
    " 'min_samples_split': 11,\n",
    " 'min_samples_leaf': 5,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 62,\n",
    " 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function works as expected, but the RFE rarely limits the number of columns very agressively.\n",
    "#df_rfe, search_alg, rfe_alg, rfe_col_log, rf_params_log = RF_RFE_RandomSearchCV(df, 13*3, 13, 13, 60, random_grid, predictors, target, max_iter=10, init_params=None, verbose=True, debugging=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_params_log#[9].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.0 Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.0 RFE CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define algorithm for modeling\n",
    "rf_params = {'n_estimators': 714,\n",
    " 'min_samples_split': 11,\n",
    " 'min_samples_leaf': 5,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 62,\n",
    " 'bootstrap': False,\n",
    "    'verbose':0,\n",
    "    'n_jobs':-1\n",
    "    }\n",
    "\n",
    "# Define initial lcnt for multi-index storing of parameters during runs\n",
    "lcnt = 0\n",
    "\n",
    "# Define loggind data frames\n",
    "rf_params_log = pd.DataFrame()\n",
    "rfe_col_log = pd.DataFrame()\n",
    "rfe_cv_log = pd.DataFrame()\n",
    "rfe_fi_log = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Looping iterations below here, don't re-run the above or you'll be starting all over!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use when not letting RFE run but not wanting to comment and affect code\n",
    "feat_count = df.shape[1]\n",
    "#feat_count = 60\n",
    "\n",
    "# create cv_iterable for this run\n",
    "cv_iterables = ts_cv_exwindow(df, 13*3, 13, 13, verbose=True)\n",
    "\n",
    "# Using generated rf_params (basic to start and then updated after each SearchCV run)\n",
    "alg = RandomForestRegressor(**rf_params)\n",
    "#alg = XGBRegressor()\n",
    "#alg = XGBRFRegressor()\n",
    "\n",
    "rfe_alg = RFECV(\n",
    "            alg, \n",
    "            step=0.1, \n",
    "            min_features_to_select=feat_count, \n",
    "            cv=cv_iterables, \n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0, \n",
    "            n_jobs=-1, \n",
    "            importance_getter='auto'\n",
    "            )\n",
    "rfe_alg\n",
    "# None = returns 60, no cv_result\n",
    "# r2 = returns 60, no cv_result\n",
    "# neg_root_mean_squared_error = returns 1000+ with cv_result\n",
    "# neg_mean_absolute_error = returns 1000+ with cv_result\n",
    "# neg_mean_squared_error = returns 1000+ with cv_result\n",
    "# max_error = returns 1000+ with cv_result\n",
    "# neg_mean_absolute_percentage_error = returns 1000+ with cv_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time, in seconds, before optimization starts (tic)\n",
    "tic = perf_counter()\n",
    "\n",
    "# Run CV optimization\n",
    "rfe_out = rfe_alg.fit(df[predictors], df[target])\n",
    "\n",
    "# Extract Selected features and information about them (rank and if included in output)\n",
    "#df_features = pd.DataFrame(columns = ['feature', 'selected', 'ranking'])\n",
    "print(df.shape[1])\n",
    "#for i in range(df[predictors].shape[1]):\n",
    "#    print(i, end='\\r')\n",
    "#    row = {'feature': df.columns[i], 'selected': rfe_out.support_[i], 'ranking': rfe_out.ranking_[i]}\n",
    "#    df_features = df_features.append(row, ignore_index=True)\n",
    "df_features = pd.DataFrame({'feature':df[predictors].columns,'selected':rfe_out.support_, 'rank':rfe_out.ranking_})\n",
    "\n",
    "df_rfe = df[df.columns[rfe_out.get_support(1)]]\n",
    "print('df_rfe shape: ', df_rfe.shape)\n",
    "\n",
    "# Get time, in seconds, after optimization finishes (toc)\n",
    "toc= perf_counter()\n",
    "\n",
    "# Calculate run_time in seconds\n",
    "run_time = toc-tic\n",
    "print(str(timedelta(seconds=run_time)))\n",
    "\n",
    "# Send a Teams message using the Benzene Forecasting Team Incoming Webhook with output info from the model\n",
    "payload = {\n",
    "    \"text\": \"RFE CV search complete. <br><br> \\\n",
    "        Run time:<br>&nbsp;&nbsp;\" + str(timedelta(seconds=run_time)) + \"<br><br> \\\n",
    "        Selected Columns:<br>\" + pd.DataFrame(df_rfe.columns)[0:59].to_html() # +  \"<br><br> \\\n",
    "}\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "#response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "#print(response.text.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rfe_fi = pd.DataFrame({'feature':df_rfe.columns, lcnt:rfe_out.estimator_.feature_importances_}).set_index('feature')\n",
    "#rfe_fi_log = pd.concat([rfe_fi_log, new_rfe_fi], axis=1)\n",
    "new_rfe_fi[0].sort_values(ascending=False)\n",
    "#rfe_fi_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(rfe_out.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(rfe_out.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current run to rfe_cv_log\n",
    "new_cv = pd.concat([pd.DataFrame.from_dict(rfe_out.cv_results_)], keys=[lcnt+1], names=['iteration', 'data'], axis=1)\n",
    "rfe_cv_log = pd.concat([rfe_cv_log, new_cv], axis=1)\n",
    "\n",
    "# Add current run to rfe_col_log \n",
    "new_rfe = pd.concat([df_features.set_index('feature')], keys=[lcnt], names=['Iteration', 'Data'], axis=1)\n",
    "rfe_col_log = pd.concat([rfe_col_log, new_rfe], axis =1)\n",
    "rfe_col_log\n",
    "#rfe_cv_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_out.get_support(0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Hyper Parameter Optimization Cross Validataion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looped lagging Hyperparameter Optimization with storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionalized RFE + HP Tuning\n",
    "\n",
    "def Lag_RF_RandomSearchCV(df, iw, sl, fh, random_grid, pred, targ, fit_shelf, lags=13, search_iters=10, init_params=None, verbose=True, debugging=False):\n",
    "    \"\"\"\n",
    "    Iteratively lag df from 1 to 'lags' and perform RandomSearchCV to optimize each over the given interval\n",
    "    Does NOT perform any prediction work, that will be done seperately this only optimizes the hyperparameters for the given lag with CV\n",
    "\n",
    "    INPUT:\n",
    "    RF_RFE_RandomSearchCV performs RFE and RandomSearch with CV to optimize RandomForestRegression()\n",
    "    df = dataframe to be processed\n",
    "    iw = initial window for CV\n",
    "    sl = step length for CV\n",
    "    fh = forecast horizion for CV\n",
    "    random_grid = dictionary of grid options to search during hyperparameter optimizataion\n",
    "    pred = list of predictors to use in first loop\n",
    "    targ = target column to be predicted\n",
    "    search_iters = number of iterations to search within random_grid (default=10)\n",
    "    init_params = initial RandomForest parameters used when peforming run 0 RFE (default=None)\n",
    "    verbose = controls standard print during run (default=True)\n",
    "    debuggin = controls debugging print during run (default=False)\n",
    "    \n",
    "    OUTPUT:\n",
    "    df_rfe = Last RFE reduced dataframe\n",
    "    search_alg = last output of RandomSearchCV optimization Model\n",
    "    rfe_alg = last output of RFECV model\n",
    "    rfe_col_log = Log of all RFE removed columns in each iteration\n",
    "    rf_params_log = log of all selected hyperparameter sets in each iteration\n",
    "    \"\"\"\n",
    "    # Configure initial RandomForestRegression Parameters\n",
    "    if init_params:\n",
    "        rf_params = init_params\n",
    "    else:\n",
    "        rf_params = {\n",
    "            'verbose':0,\n",
    "            'n_jobs':-1\n",
    "        }\n",
    "    # Open shelf to store fits\n",
    "    s = shelve.open(fit_shelf, flag='c', writeback=True)\n",
    "    if verbose: print(model_dataroot + model_shelf+' opened ')\n",
    "    # Pre-Define data frames\n",
    "    rf_params_log = pd.DataFrame()                    \n",
    "    # Create and print cv data once\n",
    "    cv_iterables = ts_cv_exwindow(df, iw, sl, fh, verbose=True)\n",
    "    # Initialize fit parameter log\n",
    "    df_fit_params = pd.DataFrame()\n",
    "    # Initizlize cv_result log\n",
    "    df_cv_results = pd.DataFrame()\n",
    "    # Initialize run_time_log\n",
    "    run_time_log = pd.DataFrame()\n",
    "    # Store original df for recall later\n",
    "    df_orig = df.copy(deep=True)\n",
    "    # Set run_date in case optimizations spans multiple days\n",
    "    run_date = date.today().strftime('%Y%m%d')\n",
    "    \n",
    "    #############################################\n",
    "    # Loop through HyperParameter optimizations #\n",
    "    #############################################\n",
    "    tic_overall = perf_counter()\n",
    "    for lcnt in range(1, lags+1, 1):\n",
    "        print('\\nLoop', str(lcnt))\n",
    "        # Get time, in seconds, before iteration starts (tic)\n",
    "        tic = perf_counter()\n",
    "        ##############################\n",
    "        # Perform Lagging Operations #\n",
    "        ##############################\n",
    "        # Revert df to original\n",
    "        df = df_orig.copy(deep=True)\n",
    "        # Shift prediction values forward lcnt steps\n",
    "        df[pred] = df[pred].shift(lcnt)\n",
    "        # Drop NaN values due to shift\n",
    "        df = df.dropna(axis=0)\n",
    "        if verbose: print('Shape of lag', lcnt, 'iteration df is', df.shape)\n",
    "        ################################\n",
    "        # Hyperparameter Optimizataion #\n",
    "        ################################\n",
    "        # create cv_iterable for this run\n",
    "        cv_iterables = ts_cv_exwindow(df, iw, sl, fh, verbose=False)\n",
    "        # Define algorithm for modeling\n",
    "        alg = RandomForestRegressor(**rf_params)\n",
    "        # Define a Random Search of fitting function that will sample the hyperparameter space and perform CV\n",
    "        search_alg = RandomizedSearchCV(  # Original values were: cv=3 , n_iter=100\n",
    "            estimator = alg, # Defined above, RandomForestRegression or XGBoost\n",
    "            param_distributions = random_grid, # Grid or distribution of hyperparameters to sample\n",
    "            n_iter = search_iters, # How many iterations of param_distribution will be sampled\n",
    "            cv = cv_iterables, # Iterable ist of CV space created by ExpandingWindowSplitter for TS\n",
    "            verbose=1, # High = more printing, 0=No Print, 10=all/max?\n",
    "            #random_state=42, # Forced random number state to allow comparison between runs\n",
    "            n_jobs = -1, # How many cores, -1 = All available\n",
    "            return_train_score = True, # Computationally expensive, but returns training scores to over/under fit comparison of CV space\n",
    "            refit = True, # will allow the use of the best estimator with .predict() after run\n",
    "            scoring='neg_mean_absolute_error' # closest to 0 is best fit\n",
    "            )\n",
    "        # Run CV optimization\n",
    "        fit_out = search_alg.fit(df[pred], df[targ])\n",
    "        # Pickle and store current model on shelf\n",
    "        s[run_date+\"_lag_\"+str(lcnt)] = fit_out\n",
    "        # Log current iteration best_params\n",
    "        new_fit_param = pd.DataFrame.from_dict(fit_out.best_params_, orient='index').T\n",
    "        new_fit_param['run_date'] = run_date\n",
    "        new_fit_param['lag'] = lcnt\n",
    "        df_fit_params = pd.concat([df_fit_params, new_fit_param], axis=0)\n",
    "        # Log current iteration cv_results_\n",
    "        new_cv_result = pd.DataFrame.from_dict(fit_out.cv_results_)\n",
    "        new_cv_result['run_date'] = run_date\n",
    "        new_cv_result['lag'] = lcnt\n",
    "        new_cv_result = new_cv_result.reset_index().rename(columns={'index':'CV_Fold'})\n",
    "        df_cv_results = pd.concat([df_cv_results, new_cv_result], axis=0, ignore_index=False)\n",
    "        # Log current fit runtime from tic-toc\n",
    "        if verbose: print('Optimization runtime was',str(timedelta(seconds=perf_counter()-tic)))\n",
    "        new_run_time = pd.DataFrame([perf_counter()-tic]).rename(columns={0:'run_time'})\n",
    "        new_run_time['run_date'] = run_date\n",
    "        new_run_time['lag'] = lcnt\n",
    "        run_time_log = pd.concat([run_time_log, new_run_time], axis=0, ignore_index=False)\n",
    "    # Log total function run_time as lag=0 value\n",
    "    total_run_time = perf_counter() - tic_overall\n",
    "    new_run_time['run_time'] = total_run_time\n",
    "    new_run_time['run_date'] = run_date\n",
    "    new_run_time['lag'] = 0\n",
    "    run_time_log = pd.concat([run_time_log, new_run_time], axis=0, ignore_index=True)\n",
    "    # Close (and sync) the shelf\n",
    "    s.close()\n",
    "    # Send a Teams message using the Benzene Forecasting Team Incoming Webhook with output info from the model\n",
    "    payload = {\n",
    "        \"text\": \"Hyperparameter search with lagging complete. <br><br> \\\n",
    "            Run time:<br>&nbsp;&nbsp;\" + str(timedelta(seconds=total_run_time)) + \"<br><br> \\\n",
    "            Total Lags:<br>\" + str(lcnt) # +  \"<br><br> \\\n",
    "    }\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    #print(response.text.encode('utf8'))\n",
    "    print('Total Runtime:', str(timedelta(seconds=total_run_time)),' H:M:S.sss')\n",
    "    return df_fit_params, df_cv_results, run_time_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 1568)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run parameters for function\n",
    "model_dataroot = '../../Data/Models/'\n",
    "model_shelf = 'Random_Forest_Models'\n",
    "fit_shelf = model_dataroot+model_shelf\n",
    "\n",
    "# Roll back if the below has been run and needs to be changed\n",
    "#df = df_full.copy(deep=True)\n",
    "\n",
    "# Set start_date for slicing df\n",
    "start_date = '2015-01-01'\n",
    "# Set end_date for slicing df\n",
    "end_date = '2018-12-31'#'2019-12-31'\n",
    "\n",
    "#df_full = df.copy(deep=True)\n",
    "df = df[start_date : end_date]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define alg search params\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 50)] # [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt'] # ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 20)] # [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 50, num = 11)] #[2, 5, 10] # [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4, 5, 10, 20] # [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False] # [True, False]\n",
    "# Define Random Forest Regressor HP grid for DV\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine where to start training for cv interval\n",
    "init_ind = df.index.get_loc('2017-12-31')\n",
    "cv_iterables = ts_cv_exwindow(df, init_ind, 1, 13, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/Models/Random_Forest_Models opened \n",
      "Initial training window ends on:  2017-12-31 00:00:00+00:00\n",
      "Number of Folds = 41\n",
      "\n",
      "Loop 1\n",
      "Shape of lag 1 iteration df is (194, 1568)\n",
      "Fitting 40 folds for each of 60 candidates, totalling 2400 fits\n",
      "Optimization runtime was 0:44:09.831187\n",
      "\n",
      "Loop 2\n",
      "Shape of lag 2 iteration df is (193, 1568)\n",
      "Fitting 39 folds for each of 60 candidates, totalling 2340 fits\n",
      "Optimization runtime was 0:59:10.680695\n",
      "\n",
      "Loop 3\n",
      "Shape of lag 3 iteration df is (192, 1568)\n",
      "Fitting 38 folds for each of 60 candidates, totalling 2280 fits\n",
      "Optimization runtime was 1:08:13.427673\n",
      "\n",
      "Loop 4\n",
      "Shape of lag 4 iteration df is (191, 1568)\n",
      "Fitting 37 folds for each of 60 candidates, totalling 2220 fits\n",
      "Optimization runtime was 1:05:18.047236\n",
      "\n",
      "Loop 5\n",
      "Shape of lag 5 iteration df is (190, 1568)\n",
      "Fitting 36 folds for each of 60 candidates, totalling 2160 fits\n",
      "Optimization runtime was 0:45:42.653456\n",
      "\n",
      "Loop 6\n",
      "Shape of lag 6 iteration df is (189, 1568)\n",
      "Fitting 35 folds for each of 60 candidates, totalling 2100 fits\n",
      "Optimization runtime was 0:53:05.201684\n",
      "\n",
      "Loop 7\n",
      "Shape of lag 7 iteration df is (188, 1568)\n",
      "Fitting 34 folds for each of 60 candidates, totalling 2040 fits\n",
      "Optimization runtime was 0:56:35.334821\n",
      "\n",
      "Loop 8\n",
      "Shape of lag 8 iteration df is (187, 1568)\n",
      "Fitting 33 folds for each of 60 candidates, totalling 1980 fits\n",
      "Optimization runtime was 0:49:49.001306\n",
      "\n",
      "Loop 9\n",
      "Shape of lag 9 iteration df is (186, 1568)\n",
      "Fitting 32 folds for each of 60 candidates, totalling 1920 fits\n",
      "Optimization runtime was 0:38:56.086350\n",
      "\n",
      "Loop 10\n",
      "Shape of lag 10 iteration df is (185, 1568)\n",
      "Fitting 31 folds for each of 60 candidates, totalling 1860 fits\n",
      "Optimization runtime was 0:46:06.902481\n",
      "\n",
      "Loop 11\n",
      "Shape of lag 11 iteration df is (184, 1568)\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "Optimization runtime was 0:41:31.707705\n",
      "\n",
      "Loop 12\n",
      "Shape of lag 12 iteration df is (183, 1568)\n",
      "Fitting 29 folds for each of 60 candidates, totalling 1740 fits\n",
      "Optimization runtime was 0:54:22.837662\n",
      "\n",
      "Loop 13\n",
      "Shape of lag 13 iteration df is (182, 1568)\n",
      "Fitting 28 folds for each of 60 candidates, totalling 1680 fits\n",
      "Optimization runtime was 0:46:46.400257\n",
      "Total Runtime: 11:09:48.152246  H:M:S.sss\n"
     ]
    }
   ],
   "source": [
    "fit_params, cv_res_log, runtimelog = Lag_RF_RandomSearchCV(df, 142, 1, 13, random_grid, predictors, target, fit_shelf, lags=13, search_iters=60, init_params=None, verbose=True, debugging=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>run_date</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "      <td>20220427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>20220427</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1044</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>20220427</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>971</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "      <td>20220427</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>20220427</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1522</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>20220427</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>20220427</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>20220427</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>88</td>\n",
       "      <td>True</td>\n",
       "      <td>20220427</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1302</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>62</td>\n",
       "      <td>True</td>\n",
       "      <td>20220427</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>73</td>\n",
       "      <td>True</td>\n",
       "      <td>20220427</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>934</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>20220427</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1853</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators min_samples_split min_samples_leaf max_features max_depth  \\\n",
       "0         1228                50                3         auto       104   \n",
       "0          604                45                5         auto        10   \n",
       "0         1044                 6                4         sqrt        73   \n",
       "0          971                 6                1         sqrt        94   \n",
       "0          236                 6                3         auto        73   \n",
       "0         1522                16               10         auto        31   \n",
       "0         1191                 2                2         sqrt        57   \n",
       "0          346                26               20         sqrt        67   \n",
       "0         1889                50                1         sqrt        88   \n",
       "0         1302                 2               20         sqrt        62   \n",
       "0          346                35               20         sqrt        73   \n",
       "0          934                50                3         sqrt        15   \n",
       "0         1853                 6                2         sqrt        15   \n",
       "\n",
       "  bootstrap  run_date  lag  \n",
       "0      True  20220427    1  \n",
       "0      True  20220427    2  \n",
       "0     False  20220427    3  \n",
       "0     False  20220427    4  \n",
       "0     False  20220427    5  \n",
       "0     False  20220427    6  \n",
       "0      True  20220427    7  \n",
       "0      True  20220427    8  \n",
       "0      True  20220427    9  \n",
       "0      True  20220427   10  \n",
       "0      True  20220427   11  \n",
       "0     False  20220427   12  \n",
       "0     False  20220427   13  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit_params.loc[(fit_params['run_date'] == '20220427') & (fit_params['lag']==2)]\n",
    "fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Fold</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>split34_train_score</th>\n",
       "      <th>split35_train_score</th>\n",
       "      <th>split36_train_score</th>\n",
       "      <th>split37_train_score</th>\n",
       "      <th>split38_train_score</th>\n",
       "      <th>split39_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>run_date</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5.183449</td>\n",
       "      <td>1.165719</td>\n",
       "      <td>0.524160</td>\n",
       "      <td>0.127320</td>\n",
       "      <td>1155</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.578478</td>\n",
       "      <td>0.483357</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>3.289010</td>\n",
       "      <td>0.608161</td>\n",
       "      <td>0.357179</td>\n",
       "      <td>0.141608</td>\n",
       "      <td>567</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-69.169215</td>\n",
       "      <td>3.322206</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>4.285176</td>\n",
       "      <td>0.687858</td>\n",
       "      <td>2.081352</td>\n",
       "      <td>4.187246</td>\n",
       "      <td>1375</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.275018</td>\n",
       "      <td>7.860413</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>102.726422</td>\n",
       "      <td>31.000900</td>\n",
       "      <td>49.501191</td>\n",
       "      <td>28.094640</td>\n",
       "      <td>2000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.953680</td>\n",
       "      <td>6.017911</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>9.111480</td>\n",
       "      <td>13.479852</td>\n",
       "      <td>2.472898</td>\n",
       "      <td>1.735500</td>\n",
       "      <td>751</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-108.388009</td>\n",
       "      <td>6.388787</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>17.952647</td>\n",
       "      <td>7.512542</td>\n",
       "      <td>13.412667</td>\n",
       "      <td>6.249237</td>\n",
       "      <td>567</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-101.687606</td>\n",
       "      <td>4.059966</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>43.787848</td>\n",
       "      <td>9.336421</td>\n",
       "      <td>23.055841</td>\n",
       "      <td>13.155508</td>\n",
       "      <td>1375</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-101.687606</td>\n",
       "      <td>4.059966</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>10.303610</td>\n",
       "      <td>13.389004</td>\n",
       "      <td>3.739020</td>\n",
       "      <td>7.606681</td>\n",
       "      <td>604</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.813726</td>\n",
       "      <td>0.657206</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>5.553453</td>\n",
       "      <td>0.750828</td>\n",
       "      <td>0.550164</td>\n",
       "      <td>0.039428</td>\n",
       "      <td>1742</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.041645</td>\n",
       "      <td>3.858449</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>6.308904</td>\n",
       "      <td>0.601813</td>\n",
       "      <td>0.560379</td>\n",
       "      <td>0.109642</td>\n",
       "      <td>1669</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.220093</td>\n",
       "      <td>8.032447</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>5.699860</td>\n",
       "      <td>0.321826</td>\n",
       "      <td>0.424006</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>1191</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-49.571675</td>\n",
       "      <td>2.181403</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>6.959343</td>\n",
       "      <td>0.931303</td>\n",
       "      <td>0.588881</td>\n",
       "      <td>0.069075</td>\n",
       "      <td>1926</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-51.757630</td>\n",
       "      <td>2.864137</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>8.112960</td>\n",
       "      <td>0.483231</td>\n",
       "      <td>0.547626</td>\n",
       "      <td>0.157998</td>\n",
       "      <td>1632</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-49.378479</td>\n",
       "      <td>2.121492</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>7.421174</td>\n",
       "      <td>0.784989</td>\n",
       "      <td>4.625845</td>\n",
       "      <td>13.470843</td>\n",
       "      <td>1559</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.400338</td>\n",
       "      <td>0.218227</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>115.310643</td>\n",
       "      <td>36.794426</td>\n",
       "      <td>45.966791</td>\n",
       "      <td>32.929762</td>\n",
       "      <td>1706</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-47.875603</td>\n",
       "      <td>3.068124</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>8.419639</td>\n",
       "      <td>3.613232</td>\n",
       "      <td>2.392535</td>\n",
       "      <td>4.126768</td>\n",
       "      <td>1448</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-95.395866</td>\n",
       "      <td>7.943016</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>32.377011</td>\n",
       "      <td>12.233267</td>\n",
       "      <td>16.603843</td>\n",
       "      <td>12.559624</td>\n",
       "      <td>1338</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-107.535722</td>\n",
       "      <td>7.240800</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>44.778962</td>\n",
       "      <td>16.803247</td>\n",
       "      <td>26.043593</td>\n",
       "      <td>13.250271</td>\n",
       "      <td>1044</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-101.687606</td>\n",
       "      <td>4.059966</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>50.721754</td>\n",
       "      <td>22.083821</td>\n",
       "      <td>25.288483</td>\n",
       "      <td>21.837973</td>\n",
       "      <td>1559</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-60.665858</td>\n",
       "      <td>2.119556</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>37.453405</td>\n",
       "      <td>16.997399</td>\n",
       "      <td>13.535762</td>\n",
       "      <td>11.233394</td>\n",
       "      <td>1338</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.752205</td>\n",
       "      <td>9.141495</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>11.890534</td>\n",
       "      <td>11.512581</td>\n",
       "      <td>9.700765</td>\n",
       "      <td>10.203330</td>\n",
       "      <td>1191</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.016314</td>\n",
       "      <td>1.005763</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>79.420124</td>\n",
       "      <td>28.957946</td>\n",
       "      <td>41.206459</td>\n",
       "      <td>28.246863</td>\n",
       "      <td>1816</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-101.687606</td>\n",
       "      <td>4.059966</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>54.348756</td>\n",
       "      <td>17.654017</td>\n",
       "      <td>21.842877</td>\n",
       "      <td>13.345529</td>\n",
       "      <td>1008</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.568105</td>\n",
       "      <td>3.825726</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>31.189266</td>\n",
       "      <td>13.278486</td>\n",
       "      <td>16.932455</td>\n",
       "      <td>7.239390</td>\n",
       "      <td>1265</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-107.462717</td>\n",
       "      <td>7.157060</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>69.885270</td>\n",
       "      <td>25.169994</td>\n",
       "      <td>38.251591</td>\n",
       "      <td>19.456434</td>\n",
       "      <td>1779</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-100.284304</td>\n",
       "      <td>12.221616</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>55.864238</td>\n",
       "      <td>21.410202</td>\n",
       "      <td>13.472146</td>\n",
       "      <td>13.117292</td>\n",
       "      <td>1302</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-101.687606</td>\n",
       "      <td>4.059966</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>17.903977</td>\n",
       "      <td>21.092084</td>\n",
       "      <td>2.948411</td>\n",
       "      <td>6.914592</td>\n",
       "      <td>530</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.502288</td>\n",
       "      <td>7.847262</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>147.533905</td>\n",
       "      <td>46.454077</td>\n",
       "      <td>38.393404</td>\n",
       "      <td>45.858994</td>\n",
       "      <td>1963</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-50.108907</td>\n",
       "      <td>2.787900</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>24.281613</td>\n",
       "      <td>21.295316</td>\n",
       "      <td>24.867837</td>\n",
       "      <td>38.545547</td>\n",
       "      <td>971</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-107.546862</td>\n",
       "      <td>6.776017</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>9.379620</td>\n",
       "      <td>9.235569</td>\n",
       "      <td>1.231468</td>\n",
       "      <td>2.228233</td>\n",
       "      <td>1265</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.206469</td>\n",
       "      <td>0.370010</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CV_Fold  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "30       30       5.183449      1.165719         0.524160        0.127320   \n",
       "31       31       3.289010      0.608161         0.357179        0.141608   \n",
       "32       32       4.285176      0.687858         2.081352        4.187246   \n",
       "33       33     102.726422     31.000900        49.501191       28.094640   \n",
       "34       34       9.111480     13.479852         2.472898        1.735500   \n",
       "35       35      17.952647      7.512542        13.412667        6.249237   \n",
       "36       36      43.787848      9.336421        23.055841       13.155508   \n",
       "37       37      10.303610     13.389004         3.739020        7.606681   \n",
       "38       38       5.553453      0.750828         0.550164        0.039428   \n",
       "39       39       6.308904      0.601813         0.560379        0.109642   \n",
       "40       40       5.699860      0.321826         0.424006        0.033909   \n",
       "41       41       6.959343      0.931303         0.588881        0.069075   \n",
       "42       42       8.112960      0.483231         0.547626        0.157998   \n",
       "43       43       7.421174      0.784989         4.625845       13.470843   \n",
       "44       44     115.310643     36.794426        45.966791       32.929762   \n",
       "45       45       8.419639      3.613232         2.392535        4.126768   \n",
       "46       46      32.377011     12.233267        16.603843       12.559624   \n",
       "47       47      44.778962     16.803247        26.043593       13.250271   \n",
       "48       48      50.721754     22.083821        25.288483       21.837973   \n",
       "49       49      37.453405     16.997399        13.535762       11.233394   \n",
       "50       50      11.890534     11.512581         9.700765       10.203330   \n",
       "51       51      79.420124     28.957946        41.206459       28.246863   \n",
       "52       52      54.348756     17.654017        21.842877       13.345529   \n",
       "53       53      31.189266     13.278486        16.932455        7.239390   \n",
       "54       54      69.885270     25.169994        38.251591       19.456434   \n",
       "55       55      55.864238     21.410202        13.472146       13.117292   \n",
       "56       56      17.903977     21.092084         2.948411        6.914592   \n",
       "57       57     147.533905     46.454077        38.393404       45.858994   \n",
       "58       58      24.281613     21.295316        24.867837       38.545547   \n",
       "59       59       9.379620      9.235569         1.231468        2.228233   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "30               1155                      11                      2   \n",
       "31                567                       2                     10   \n",
       "32               1375                      50                      3   \n",
       "33               2000                      40                     10   \n",
       "34                751                      45                     10   \n",
       "35                567                      26                     20   \n",
       "36               1375                      16                     20   \n",
       "37                604                      16                      4   \n",
       "38               1742                       2                     20   \n",
       "39               1669                      50                      2   \n",
       "40               1191                      16                      5   \n",
       "41               1926                      35                      1   \n",
       "42               1632                      16                      5   \n",
       "43               1559                       2                      3   \n",
       "44               1706                      26                      2   \n",
       "45               1448                      40                      2   \n",
       "46               1338                      45                      1   \n",
       "47               1044                      11                     20   \n",
       "48               1559                      21                     10   \n",
       "49               1338                      40                      1   \n",
       "50               1191                      26                      1   \n",
       "51               1816                      21                     20   \n",
       "52               1008                      35                      2   \n",
       "53               1265                      45                      2   \n",
       "54               1779                      50                      1   \n",
       "55               1302                      35                     20   \n",
       "56                530                      50                      3   \n",
       "57               1963                       2                     10   \n",
       "58                971                       6                     20   \n",
       "59               1265                      11                      5   \n",
       "\n",
       "   param_max_features param_max_depth  ... split34_train_score  \\\n",
       "30               sqrt              94  ...                 NaN   \n",
       "31               sqrt            None  ...                 NaN   \n",
       "32               sqrt              62  ...                 NaN   \n",
       "33               auto              41  ...                 NaN   \n",
       "34               sqrt              62  ...                 NaN   \n",
       "35               auto              78  ...                 NaN   \n",
       "36               auto              78  ...                 NaN   \n",
       "37               sqrt              41  ...                 NaN   \n",
       "38               sqrt              78  ...                 NaN   \n",
       "39               sqrt              73  ...                 NaN   \n",
       "40               sqrt            None  ...                 NaN   \n",
       "41               sqrt              78  ...                 NaN   \n",
       "42               sqrt              73  ...                 NaN   \n",
       "43               sqrt              41  ...                 NaN   \n",
       "44               auto              20  ...                 NaN   \n",
       "45               sqrt              15  ...                 NaN   \n",
       "46               auto             110  ...                 NaN   \n",
       "47               auto              25  ...                 NaN   \n",
       "48               auto              78  ...                 NaN   \n",
       "49               auto              10  ...                 NaN   \n",
       "50               sqrt              25  ...                 NaN   \n",
       "51               auto              20  ...                 NaN   \n",
       "52               auto              31  ...                 NaN   \n",
       "53               auto              15  ...                 NaN   \n",
       "54               auto              88  ...                 NaN   \n",
       "55               auto              99  ...                 NaN   \n",
       "56               sqrt              88  ...                 NaN   \n",
       "57               auto              25  ...                 NaN   \n",
       "58               auto            None  ...                 NaN   \n",
       "59               sqrt             104  ...                 NaN   \n",
       "\n",
       "   split35_train_score  split36_train_score  split37_train_score  \\\n",
       "30                 NaN                  NaN                  NaN   \n",
       "31                 NaN                  NaN                  NaN   \n",
       "32                 NaN                  NaN                  NaN   \n",
       "33                 NaN                  NaN                  NaN   \n",
       "34                 NaN                  NaN                  NaN   \n",
       "35                 NaN                  NaN                  NaN   \n",
       "36                 NaN                  NaN                  NaN   \n",
       "37                 NaN                  NaN                  NaN   \n",
       "38                 NaN                  NaN                  NaN   \n",
       "39                 NaN                  NaN                  NaN   \n",
       "40                 NaN                  NaN                  NaN   \n",
       "41                 NaN                  NaN                  NaN   \n",
       "42                 NaN                  NaN                  NaN   \n",
       "43                 NaN                  NaN                  NaN   \n",
       "44                 NaN                  NaN                  NaN   \n",
       "45                 NaN                  NaN                  NaN   \n",
       "46                 NaN                  NaN                  NaN   \n",
       "47                 NaN                  NaN                  NaN   \n",
       "48                 NaN                  NaN                  NaN   \n",
       "49                 NaN                  NaN                  NaN   \n",
       "50                 NaN                  NaN                  NaN   \n",
       "51                 NaN                  NaN                  NaN   \n",
       "52                 NaN                  NaN                  NaN   \n",
       "53                 NaN                  NaN                  NaN   \n",
       "54                 NaN                  NaN                  NaN   \n",
       "55                 NaN                  NaN                  NaN   \n",
       "56                 NaN                  NaN                  NaN   \n",
       "57                 NaN                  NaN                  NaN   \n",
       "58                 NaN                  NaN                  NaN   \n",
       "59                 NaN                  NaN                  NaN   \n",
       "\n",
       "    split38_train_score  split39_train_score  mean_train_score  \\\n",
       "30                  NaN                  NaN        -13.578478   \n",
       "31                  NaN                  NaN        -69.169215   \n",
       "32                  NaN                  NaN        -70.275018   \n",
       "33                  NaN                  NaN        -71.953680   \n",
       "34                  NaN                  NaN       -108.388009   \n",
       "35                  NaN                  NaN       -101.687606   \n",
       "36                  NaN                  NaN       -101.687606   \n",
       "37                  NaN                  NaN        -21.813726   \n",
       "38                  NaN                  NaN        -79.041645   \n",
       "39                  NaN                  NaN        -70.220093   \n",
       "40                  NaN                  NaN        -49.571675   \n",
       "41                  NaN                  NaN        -51.757630   \n",
       "42                  NaN                  NaN        -49.378479   \n",
       "43                  NaN                  NaN         -7.400338   \n",
       "44                  NaN                  NaN        -47.875603   \n",
       "45                  NaN                  NaN        -95.395866   \n",
       "46                  NaN                  NaN       -107.535722   \n",
       "47                  NaN                  NaN       -101.687606   \n",
       "48                  NaN                  NaN        -60.665858   \n",
       "49                  NaN                  NaN        -97.752205   \n",
       "50                  NaN                  NaN        -37.016314   \n",
       "51                  NaN                  NaN       -101.687606   \n",
       "52                  NaN                  NaN        -66.568105   \n",
       "53                  NaN                  NaN       -107.462717   \n",
       "54                  NaN                  NaN       -100.284304   \n",
       "55                  NaN                  NaN       -101.687606   \n",
       "56                  NaN                  NaN        -70.502288   \n",
       "57                  NaN                  NaN        -50.108907   \n",
       "58                  NaN                  NaN       -107.546862   \n",
       "59                  NaN                  NaN        -16.206469   \n",
       "\n",
       "    std_train_score  run_date  lag  \n",
       "30         0.483357  20220427   13  \n",
       "31         3.322206  20220427   13  \n",
       "32         7.860413  20220427   13  \n",
       "33         6.017911  20220427   13  \n",
       "34         6.388787  20220427   13  \n",
       "35         4.059966  20220427   13  \n",
       "36         4.059966  20220427   13  \n",
       "37         0.657206  20220427   13  \n",
       "38         3.858449  20220427   13  \n",
       "39         8.032447  20220427   13  \n",
       "40         2.181403  20220427   13  \n",
       "41         2.864137  20220427   13  \n",
       "42         2.121492  20220427   13  \n",
       "43         0.218227  20220427   13  \n",
       "44         3.068124  20220427   13  \n",
       "45         7.943016  20220427   13  \n",
       "46         7.240800  20220427   13  \n",
       "47         4.059966  20220427   13  \n",
       "48         2.119556  20220427   13  \n",
       "49         9.141495  20220427   13  \n",
       "50         1.005763  20220427   13  \n",
       "51         4.059966  20220427   13  \n",
       "52         3.825726  20220427   13  \n",
       "53         7.157060  20220427   13  \n",
       "54        12.221616  20220427   13  \n",
       "55         4.059966  20220427   13  \n",
       "56         7.847262  20220427   13  \n",
       "57         2.787900  20220427   13  \n",
       "58         6.776017  20220427   13  \n",
       "59         0.370010  20220427   13  \n",
       "\n",
       "[30 rows x 99 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_log.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_time</th>\n",
       "      <th>run_date</th>\n",
       "      <th>lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2649.831570</td>\n",
       "      <td>20220427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3550.681066</td>\n",
       "      <td>20220427</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4093.428042</td>\n",
       "      <td>20220427</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3918.047604</td>\n",
       "      <td>20220427</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2742.653823</td>\n",
       "      <td>20220427</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3185.202061</td>\n",
       "      <td>20220427</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3395.335193</td>\n",
       "      <td>20220427</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2989.001670</td>\n",
       "      <td>20220427</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2336.086703</td>\n",
       "      <td>20220427</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2766.902851</td>\n",
       "      <td>20220427</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2491.708086</td>\n",
       "      <td>20220427</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3262.838031</td>\n",
       "      <td>20220427</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2806.400620</td>\n",
       "      <td>20220427</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40188.152246</td>\n",
       "      <td>20220427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run_time  run_date  lag\n",
       "0    2649.831570  20220427    1\n",
       "1    3550.681066  20220427    2\n",
       "2    4093.428042  20220427    3\n",
       "3    3918.047604  20220427    4\n",
       "4    2742.653823  20220427    5\n",
       "5    3185.202061  20220427    6\n",
       "6    3395.335193  20220427    7\n",
       "7    2989.001670  20220427    8\n",
       "8    2336.086703  20220427    9\n",
       "9    2766.902851  20220427   10\n",
       "10   2491.708086  20220427   11\n",
       "11   3262.838031  20220427   12\n",
       "12   2806.400620  20220427   13\n",
       "13  40188.152246  20220427    0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtimelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default storage location for shelve of models\n",
    "model_dataroot = '../../Data/Models/'\n",
    "model_shelf = 'Random_Forest_Models.db'\n",
    "#model_shelf = date.today().strftime('%Y%m%d')+'_Shelved_Models.db'\n",
    "\n",
    "# Open shelve object on first run\n",
    "if os.path.isdir(model_dataroot):\n",
    "    s = shelve.open(model_dataroot+model_shelf, flag='c', writeback=True)\n",
    "    print(model_dataroot + model_shelf+' opened ')\n",
    "else:\n",
    "    os.mkdir(model_dataroot)\n",
    "    print('Shelve storage location did not exist. It has been created\\n')\n",
    "    s = shelve.open(model_dataroot+model_shelf, flag='c', writeback=True)\n",
    "    print(model_dataroot + model_shelf+' opened ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rfe = df.copy(deep=True)\n",
    "\n",
    "# create cv_iterable for this run\n",
    "cv_iterables = ts_cv_exwindow(df_rfe, 13*3, 13, 13, verbose=True)\n",
    "\n",
    "# Define algorithm for modeling\n",
    "# Use no bias when beginnng the search so do not include rf_params\n",
    "alg = RandomForestRegressor(verbose=0, n_jobs=-1) #**rf_params)\n",
    "\n",
    "# Define alg search params\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 50)] # [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt'] # ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 20)] # [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 50, num = 11)] #[2, 5, 10] # [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4, 5, 10, 20] # [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False] # [True, False]\n",
    "\n",
    "# Define Random Forest Regressor HP grid for DV\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "               }\n",
    "\n",
    "# Define rg_str which is a readable version of random_grid used in json payload for Teams notification\n",
    "rg_str = '<br>&nbsp; n_estimators:'+ str(n_estimators) + \\\n",
    "               '<br>&nbsp; max_features: '+ str(max_features) +\\\n",
    "               '<br>&nbsp; max_depth: ;'+ str(max_depth) + \\\n",
    "               '<br>&nbsp; min_samples_split: '+ str(min_samples_split) + \\\n",
    "               '<br>&nbsp; min_samples_leaf: '+ str(min_samples_leaf) + \\\n",
    "               '<br>&nbsp; bootstrap: '+ str(bootstrap)\n",
    "\n",
    "print(random_grid)\n",
    "#print(rg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Random Search of fitting function that will sample the hyperparameter space and perform CV\n",
    "# \"\"\"\n",
    "search_alg = RandomizedSearchCV(  # Original values were: cv=3 , n_iter=100\n",
    "    estimator = alg, # Defined above, RandomForestRegression or XGBoost\n",
    "    param_distributions = random_grid, # Grid or distribution of hyperparameters to sample\n",
    "    n_iter = 2, # How many iterations of param_distribution will be sampled\n",
    "    cv = cv_iterables, # Iterable ist of CV space created by ExpandingWindowSplitter for TS\n",
    "    verbose=1, # High = more printing, 0=No Print, 10=all/max?\n",
    "    #random_state=42, # Forced random number state to allow comparison between runs\n",
    "    n_jobs = -1, # How many cores, -1 = All available\n",
    "    return_train_score = True, # Computationally expensive, but returns training scores to over/under fit comparison of CV space\n",
    "    refit = True, # will allow the use of the best estimator with .predict() after run\n",
    "    scoring='neg_mean_absolute_error' # closest to 0 is best fit\n",
    "    ) \n",
    "\"\"\"\n",
    "# Define a Grid Search of fitting function that will sample the hyperparameter space and perform CV\n",
    "search_alg = GridSearchCV(  # Original values were: cv=3 , n_iter=100\n",
    "    estimator = alg, # Defined above, RandomForestRegression or XGBoost\n",
    "    param_grid = random_grid, # Grid or distribution of hyperparameters to sample\n",
    "    cv = cv_iterables, # Iterable ist of CV space created by ExpandingWindowSplitter for TS\n",
    "    verbose=1, # High = more printing, 0=No Print, 10=all/max?\n",
    "    n_jobs = -1, # How many cores, -1 = All available\n",
    "    return_train_score = True, # Computationally expensive, but returns training scores to over/under fit comparison of CV space\n",
    "    refit = True, # will allow the use of the best estimator with .predict() after run\n",
    "    scoring='neg_mean_absolute_error', # closest to 0 is best fit  \n",
    "    ) \n",
    "\"\"\"\n",
    "print(search_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get time, in seconds, before optimization starts (tic)\n",
    "tic = perf_counter()\n",
    "\n",
    "# Run CV optimization\n",
    "fit_out = search_alg.fit(df_rfe[predictors], df_rfe[target])\n",
    "\n",
    "# Get time, in seconds, after optimization finishes (toc)\n",
    "toc= perf_counter()\n",
    "\n",
    "# Calculate run_time in seconds\n",
    "run_time = toc-tic\n",
    "print(str(timedelta(seconds=run_time)))\n",
    "\n",
    "# Send a Teams message using the Benzene Forecasting Team Incoming Webhook with output info from the model\n",
    "payload = {\n",
    "    \"text\": \"Grid search complete. <br><br> \\\n",
    "        Run time:<br>&nbsp;&nbsp;\" + str(timedelta(seconds=run_time)) + \"<br><br> \\\n",
    "        Best Score:<br>&nbsp;&nbsp;\" + str(abs(fit_out.best_score_)) + \"<br><br> \\\n",
    "        Best Params:<br>\" + str(fit_out.best_params_).replace(',',',<br>&nbsp;&nbsp;') + '<br><br> \\\n",
    "        Grid Search Params:' + rg_str\n",
    "}\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "#response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "#print(response.text.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_out.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_fit_params = pd.DataFrame.from_dict(fit_out.best_params_, orient='index').T\n",
    "df_fit_params['run_date'] = date.today().strftime('%Y%m%d')\n",
    "df_fit_params['lag'] = 1\n",
    "#df_fit_params = df_fit_params.set_index(['run_date'])\n",
    "\n",
    "new_fit_param = pd.DataFrame.from_dict(fit_out.best_params_, orient='index').T\n",
    "new_fit_param['run_date'] = date.today().strftime('%Y%m%d')\n",
    "new_fit_param['lag'] = 2\n",
    "#new_fit_param = new_fit_param.set_index(['run_date'])\n",
    "df_fit_params = pd.concat([df_fit_params, new_fit_param], axis=0)\n",
    "\n",
    "new_fit_param = pd.DataFrame.from_dict(fit_out.best_params_, orient='index').T\n",
    "new_fit_param['run_date'] = '20220428'\n",
    "new_fit_param['lag'] = 1\n",
    "#new_fit_param = new_fit_param.set_index(['date'])\n",
    "df_fit_params = pd.concat([df_fit_params, new_fit_param], axis=0)\n",
    "\n",
    "new_fit_param = pd.DataFrame.from_dict(fit_out.best_params_, orient='index').T\n",
    "new_fit_param['run_date'] = '20220428'\n",
    "new_fit_param['lag'] = 2\n",
    "#new_fit_param = new_fit_param.set_index(['date'])\n",
    "df_fit_params = pd.concat([df_fit_params, new_fit_param], axis=0)\n",
    "\n",
    "#df_fit_params = df_fit_params.set_index(['run_date', 'lag'])\n",
    "#df_fit_params[slice('20220427')][slice(1,2)]\n",
    "\n",
    "df_fit_params[(df_fit_params['run_date']==max(df_fit_params['run_date']))]# & (df_fit_params['lag']==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set rf_params to output for next loop\n",
    "rf_params = fit_out.best_params_\n",
    "\n",
    "# Log current iteration rf_params\n",
    "best_param_df = pd.DataFrame.from_dict(fit_out.best_params_, orient='index')#.rename(columns={0:lcnt})\n",
    "\n",
    "rf_params_log = pd.concat([rf_params_log, best_param_df], axis =1)\n",
    "rf_params_log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increment lcnt for next iteration\n",
    "lcnt = lcnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estimator:\\n\\t\", fit_out.best_estimator_)\n",
    "print(\"\\nBest Params:\\n\\t\", fit_out.best_params_)\n",
    "print(\"\\nBest Index Model:\\n\\t\", fit_out.best_index_)\n",
    "#print(\"CV Results:\", fit_out.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the future values and compare them to the knowns\n",
    "#df_predict = pd.DataFrame(df_predict).reindex_like(df_forecast)\n",
    "df_predict = pd.DataFrame(fit_out.predict(df_forecast[predictors])).set_index(df_forecast.index).rename(columns={0:'prediction'})\n",
    "df_predict = df_predict.shift(-fshift).dropna(axis=0)\n",
    "df_predict = pd.concat([df_full[ df_predict.index[0] : df_predict.index[-1] ][target], df_predict], axis=1)\n",
    "df_predict['pct_error'] = abs( df_predict[target] - df_predict['prediction']) / df_predict[target] * 100\n",
    "\n",
    "# Send Teams Message of findings\n",
    "payload = {\n",
    "    \"text\": \"Prediction complete. <br>\" \\\n",
    "         + df_predict.to_html()\n",
    "}\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "print(response.text.encode('utf8'))\n",
    "\n",
    "\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Organization and Testing\n",
    "\n",
    "Shelve (Pickle)\n",
    "\n",
    "Multi-index DataFrame --> Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time_log = pd.DataFrame()\n",
    "#new_run_time=pd.DataFrame()\n",
    "new_run_time = pd.DataFrame([22.45855]).rename(columns={0:'run_time'})\n",
    "new_run_time['run_date'] = '20220427'\n",
    "new_run_time['lag'] = lcnt\n",
    "run_time_log = pd.concat([run_time_log, new_run_time], axis=0)\n",
    "\n",
    "new_run_time = pd.DataFrame([24.5855]).rename(columns={0:'run_time'})\n",
    "new_run_time['run_date'] = '20220427'\n",
    "new_run_time['lag'] = lcnt+1\n",
    "run_time_log = pd.concat([run_time_log, new_run_time], axis=0)\n",
    "\n",
    "run_time_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result_log = pd.DataFrame.from_dict(fit_out.cv_results_)\n",
    "cv_result_log['lag'] = lcnt\n",
    "cv_result_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store dictionary inside of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry1 = pd.DataFrame([['20220427',{'Key1':'Value1', 'key2':'value2'}]], columns=['date','params']).set_index('date')\n",
    "entry2 = pd.DataFrame([['20220428',{'Key1':'Value1', 'key2':'value2'}]], columns=['date','params']).set_index('date')\n",
    "\n",
    "param_log = pd.concat([entry1, entry2], axis=0)\n",
    "param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_log[param_log.index == '20220428'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Key1':'Value1', 'key2':'value2'}\n",
    "dict2 = {'Key3':'Value3', 'key4':'value4'}\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df['First'] = dict1.items()\n",
    "test_df['Second'] = dict2.items()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqlite3 - Requires specific local driver in Power BI that isn't installable. Use Parquet instead for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shelve - will work great for storing models over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default storage location for files\n",
    "model_dataroot = '../../Data/Models/'\n",
    "model_shelf = date.today().strftime('%Y%m%d')+'_Shelved_Models.db'\n",
    "\n",
    "# Export Parquet file\n",
    "if os.path.isdir(model_dataroot):\n",
    "    # Export Data\n",
    "    s = shelve.open(model_dataroot+model_shelf, flag='c', writeback=True)\n",
    "    print(model_dataroot + model_shelf+' opened ')\n",
    "else:\n",
    "    os.mkdir(model_dataroot)\n",
    "    print('Shelve storage location did not exist. It has been created\\n')\n",
    "    s = shelve.open(model_dataroot+model_shelf, flag='c', writeback=True)\n",
    "    print(model_dataroot + model_shelf+' opened ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Fast Optimization3'] = fit_out\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = s['Fast Optimization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.predict(df_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation and Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series WFV and Optimization\n",
    "* https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=24f6be86f95bfc1ec246dee7dcdd455e0a84a872&device=unknown&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c616e2d747572696e672d696e737469747574652f736b74696d652f323466366265383666393562666331656332343664656537646364643435356530613834613837322f6578616d706c65732f77696e646f775f73706c6974746572732e6970796e62&logged_in=false&nwo=alan-turing-institute%2Fsktime&path=examples%2Fwindow_splitters.ipynb&platform=android&repository_id=156401841&repository_type=Repository&version=98\n",
    "* https://quantile.app/blog/cross_validation\n",
    "* https://towardsdatascience.com/dont-use-k-fold-validation-for-time-series-forecasting-30b724aaea64\n",
    "* https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "* https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n",
    "* https://machinelearningmastery.com/what-is-bayesian-optimization/\n",
    "* https://www.analyticsvidhya.com/blog/2021/05/bayesian-optimization-bayes_opt-or-hyperopt/\n",
    "* https://www.kdnuggets.com/2019/07/xgboost-random-forest-bayesian-optimisation.html\n",
    "\n",
    "#### Error\n",
    "* https://towardsdatascience.com/forecast-kpi-rmse-mae-mape-bias-cdc5703d242d#:~:text=The%20Mean%20Absolute%20Percentage%20Error,average%20of%20the%20percentage%20errors.\n",
    "\n",
    "#### SKTime Documentation:\n",
    "* https://www.sktime.org/en/latest/examples/01_forecasting.html\n",
    "\n",
    "#### SKforcast (PIP, not installed in environment):\n",
    "* https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python-scikitlearn.html\n",
    "\n",
    "#### Incremental Forecast loop using standard sklearn algorithms:\n",
    "* https://www.analyticsvidhya.com/blog/2021/06/random-forest-for-time-series-forecasting/\n",
    "* https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1\n",
    "* https://www.ethanrosenthal.com/2019/02/18/time-series-for-scikit-learn-people-part3/\n",
    "\n",
    "#### TS with Random Forest\n",
    "* https://towardsdatascience.com/multivariate-time-series-forecasting-using-random-forest-2372f3ecbad1\n",
    "* https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/\n",
    "\n",
    "#### ARIMA\n",
    "* https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/\n",
    "\n",
    "#### Prophet \n",
    "* https://towardsdatascience.com/implementing-facebook-prophet-efficiently-c241305405a3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb5848bbb94c62469d14a65c30db01332f25fa6930c7bf154b7b5e2e34ee3709"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37_benzene': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
