{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT was asked:\n",
    "\n",
    "Can you give me python code that will perform LSTM to predict google stock price? I want to load the data from yfinance and perform looped hyperparameter optimization on 3 folds of historical data. I'd also like a summary graph that shows the fits for each of the optimization runs. and a prediction for 30 days from the best algorithm. Please break the output into 3 parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please give my python code that will: import google stock price from yfinance, predict future values using lstm, optimize hyperparmeters with 3 fold cross validation, plot fits for each model. Please break the code into 4 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Data Pre Processing and Model definition\n",
    "\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set the time step\n",
    "timestep = 60\n",
    "\n",
    "# Download the data from Yahoo Finance\n",
    "stock_data = yf.download('GOOG', start='2010-01-01', end='2022-02-21')\n",
    "\n",
    "# Create a new dataframe with only the 'Close' column\n",
    "data = stock_data.filter(['Close'])\n",
    "\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# Create the training dataset\n",
    "train_data = scaled_data[:int(0.8*len(dataset))]\n",
    "\n",
    "# Split the data into x_train and y_train datasets\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(timestep, len(train_data)):\n",
    "    x_train.append(train_data[i-timestep:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "# Convert the x_train and y_train datasets to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Reshape the data\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "# Define the LSTM model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14044\\4215781124.py:4: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=64, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {}\n",
      "Best score: -5.0032270034231864e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1609f46f8e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning with grid search and time series cross-validation\n",
    "\n",
    "# Wrap the Keras model in a scikit-learn regressor\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    #'layers': [[100, 100], [150, 100], [100, 50, 25]],\n",
    "    #'batch_size': [64, 128],\n",
    "    #'epochs': [50, 100],\n",
    "    #'dropout_rate': [0.2, 0.3],\n",
    "    #'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Perform a grid search with time series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=tscv, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best score:', grid_search.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_.model\n",
    "\n",
    "# Train the best model on all of the training data\n",
    "best_model.fit(x_train, y_train, epochs=50, batch_size=64, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 21ms/step\n",
      "Train RMSE: 21.93460536956099\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Plot the training history\u001b[39;00m\n\u001b[0;32m     13\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m plt\u001b[39m.\u001b[39mplot(best_model\u001b[39m.\u001b[39;49mhistory\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mTraining History\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model evaluation and training history plot\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "train_predict = best_model.predict(x_train)\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "rmse = np.sqrt(np.mean(np.square(train_predict - y_train)))\n",
    "print('Train RMSE:', rmse)\n",
    "\n",
    "# Plot the training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(best_model.history.history['loss'], label='Training Loss')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting the best fit from the past\n",
    "\n",
    "# Create the testing dataset\n",
    "test_data = scaled_data[int(0.8*len(dataset))-timestep:]\n",
    "x_test = []\n",
    "for i in range(timestep, len(test_data)):\n",
    "    x_test.append(test_data[i-timestep:i, 0])\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Generate predictions for the testing dataset\n",
    "test_predict = best_model.predict(x_test)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "\n",
    "# Plot the actual stock prices and the predicted prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data.index[int(0.8*len(dataset)):], data['Close'][int(0.8*len(dataset)):], label='Actual')\n",
    "plt.plot(data.index[int(0.8*len(dataset))+timestep:len(data)], test_predict, label='Predicted')\n",
    "plt.title('Google Stock Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting the next 60 days\n",
    "\n",
    "# Make predictions for the next 60 days\n",
    "future_predictions = []\n",
    "last_sequence = x_test[-1:]\n",
    "for i in range(60):\n",
    "    next_prediction = best_model.predict(last_sequence)\n",
    "    future_predictions.append(next_prediction)\n",
    "    last_sequence = np.append(last_sequence[:,1:,:], [[next_prediction]], axis=1)\n",
    "future_predictions = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "# Create a dataframe with the predicted prices for the next 60 days\n",
    "prediction_dates = pd.date_range(start=data.index[-1]+pd.Timedelta(days=1), periods=60, freq='D')\n",
    "future_prices = pd.DataFrame(future_predictions, index=prediction_dates, columns=['Predicted'])\n",
    "\n",
    "# Plot the actual stock prices and the predicted prices for the next 60 days\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data.index[int(0.8*len(dataset)):], data['Close'][int(0.8*len(dataset)):], label='Actual')\n",
    "plt.plot(data.index[int(0.8*len(dataset))+timestep:len(data)], test_predict, label='Past Predictions')\n",
    "plt.plot(future_prices.index, future_prices['Predicted'], label='Future Predictions')\n",
    "plt.title('Google Stock Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('py39_lstm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1dbe1a3b15ba98fa3ec9be38ad6a4e6e5f157a073434d046fa089a87b1165d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
